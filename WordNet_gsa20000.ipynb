{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Summary of WordNet \n",
        "\n",
        "WordNet is a word and lexial database that consist of words and all of its forms. WordNet also defines and gives out exmaples of how to use these words. "
      ],
      "metadata": {
        "id": "yE8TiLg6bhcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet as wn\n",
        "#Select a noun. Output all synsets.\n",
        "wn.synsets('work')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "C1UsXSVVbl82",
        "outputId": "0b94e57a-60f9-4daf-c5f8-bdd5b6315053"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('work.n.01'),\n",
              " Synset('work.n.02'),\n",
              " Synset('employment.n.02'),\n",
              " Synset('study.n.02'),\n",
              " Synset('work.n.05'),\n",
              " Synset('workplace.n.01'),\n",
              " Synset('oeuvre.n.01'),\n",
              " Synset('work.v.01'),\n",
              " Synset('work.v.02'),\n",
              " Synset('work.v.03'),\n",
              " Synset('function.v.01'),\n",
              " Synset('work.v.05'),\n",
              " Synset('exercise.v.03'),\n",
              " Synset('make.v.36'),\n",
              " Synset('work.v.08'),\n",
              " Synset('work.v.09'),\n",
              " Synset('work.v.10'),\n",
              " Synset('bring.v.03'),\n",
              " Synset('work.v.12'),\n",
              " Synset('cultivate.v.02'),\n",
              " Synset('work.v.14'),\n",
              " Synset('influence.v.01'),\n",
              " Synset('work.v.16'),\n",
              " Synset('work.v.17'),\n",
              " Synset('work.v.18'),\n",
              " Synset('work.v.19'),\n",
              " Synset('shape.v.02'),\n",
              " Synset('work.v.21'),\n",
              " Synset('knead.v.01'),\n",
              " Synset('exploit.v.01'),\n",
              " Synset('solve.v.01'),\n",
              " Synset('ferment.v.03'),\n",
              " Synset('sour.v.01'),\n",
              " Synset('work.v.27')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select one synset from the list of synsets. Extract its definition, usage examples, and lemmas.\n",
        "wn.synset('work.n.01').definition()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6vMFYqG1dep_",
        "outputId": "046f6d1b-37d3-415e-a1e0-21c1cd7e85ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'activity directed toward making or doing something'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('work.n.01').examples()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXcnhUu8dn_1",
        "outputId": "b80060b3-2e9d-408b-ad1e-9a77952b5bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['she checked several points needing further work']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "wn.synset('work.n.01').lemmas()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuHrT195dqGl",
        "outputId": "5ce88986-a82d-46ec-c4b8-9eefda0bdfd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('work.n.01.work')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "work = wn.synset('work.n.01')\n",
        "hyper = work.hypernyms()[0]\n",
        "t = wn.synset('entity.n.01')\n",
        "while hyper:\n",
        "    print(hyper)\n",
        "    if hyper == t:\n",
        "        break\n",
        "    if hyper.hypernyms():\n",
        "        hyper = hyper.hypernyms()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hq_dqsPqeuSD",
        "outputId": "243007f8-8281-43f6-acb5-d14323ed3112"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('activity.n.01')\n",
            "Synset('act.n.02')\n",
            "Synset('event.n.01')\n",
            "Synset('psychological_feature.n.01')\n",
            "Synset('abstraction.n.06')\n",
            "Synset('entity.n.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Observation\n",
        "\n",
        "I feel that WordNet works better with nouns, as sometimes it has multiple definitions of a single word. Unlike other word forms, where it might has very few definitions to none. Also, I noticed that WordNet works very well for noun words, as it provides a hierarchy of the word (until the word entity). Also, WordNet can define a word, state the lemmatizations of the word, and provide examples of the word.  \n",
        "\n",
        "The noun I used was work, and the definition I got is \"activity directed toward making or doing something,\" which I believe to be accurate. The examples I got is \"she checked several points needing further work,\" which I also believe is accurate. And the lemma I received is 'work.n.01.work'\n",
        "\n",
        "For the WordNet hierarchy, I received these words: activity, act, event, psychological_feature, abstraction, and entity, which are also similar to dance. "
      ],
      "metadata": {
        "id": "Lc83kFpIjimV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a couple of sentences observing the way that WordNet is organized for nouns."
      ],
      "metadata": {
        "id": "3QuMoqebhGOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Output the following (or an empty list if none exist): hypernyms, hyponyms, meronyms, holonyms, antonym.\n",
        "wn.synset('work.n.01').hypernyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeRjGIx2hIVX",
        "outputId": "1acc214b-943c-45e1-8b5f-2cd7e4fd36bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('activity.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('work.n.01').hyponyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-qa-Tb3he7-",
        "outputId": "24bbd16c-ced9-4561-a7d8-fa4d697b6250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('action.n.10'),\n",
              " Synset('busywork.n.01'),\n",
              " Synset('care.n.01'),\n",
              " Synset('coursework.n.01'),\n",
              " Synset('duty.n.02'),\n",
              " Synset('heavy_lifting.n.01'),\n",
              " Synset('housewifery.n.01'),\n",
              " Synset('housework.n.01'),\n",
              " Synset('investigation.n.02'),\n",
              " Synset('ironing.n.02'),\n",
              " Synset('job.n.06'),\n",
              " Synset('job.n.07'),\n",
              " Synset('labor.n.02'),\n",
              " Synset('logging.n.01'),\n",
              " Synset('loose_end.n.01'),\n",
              " Synset('mission.n.04'),\n",
              " Synset('nightwork.n.01'),\n",
              " Synset('operation.n.07'),\n",
              " Synset('paperwork.n.01'),\n",
              " Synset('service.n.01'),\n",
              " Synset('shining.n.01'),\n",
              " Synset('spadework.n.01'),\n",
              " Synset('subbing.n.01'),\n",
              " Synset('timework.n.01'),\n",
              " Synset('undertaking.n.01'),\n",
              " Synset('wash.n.02'),\n",
              " Synset('welfare_work.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('work.n.01').part_meronyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEusX5r_hi8R",
        "outputId": "19f500b2-7e48-45b7-effc-5bd36d45c497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('work.n.01').part_holonyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjcYUoVVh27u",
        "outputId": "bfeef007-b0cb-4ea3-cfaa-5a5831d9224e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = wn.synset('work.n.01')\n",
        "w.lemmas()[0].antonyms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCtBk1jyh8HD",
        "outputId": "a04c1cb1-c087-47a9-a177-c41bec46b634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select a verb. Output all synsets.\n",
        "wn.synsets('dance')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRSHAkQTjhUl",
        "outputId": "807eb359-806d-483f-e315-af0c10a42331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('dance.n.01'),\n",
              " Synset('dance.n.02'),\n",
              " Synset('dancing.n.01'),\n",
              " Synset('dance.n.04'),\n",
              " Synset('dance.v.01'),\n",
              " Synset('dance.v.02'),\n",
              " Synset('dance.v.03')]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('dance.v.01').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FsgtnT2uj1S6",
        "outputId": "5dfd1bf4-5dea-4d08-fd38-74792cb346f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'move in a graceful and rhythmical way'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('dance.v.01').examples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf3qM1ynj4I3",
        "outputId": "9f3ef32f-784a-4b67-d12d-d7fb92b4731c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The young girl danced into the room']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('dance.v.01').lemmas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecfP4478j65x",
        "outputId": "2f4f2751-f612-4bd5-9a56-9a8e0ff8312c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Lemma('dance.v.01.dance')]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# traversing \n",
        "act = wn.synset('dance.v.01')\n",
        "hyper = act.hypernyms()[0]\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print(hyper)\n",
        "    if hyper.hypernyms():\n",
        "        hyper = hyper.hypernyms()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-g5fNNvkYoS",
        "outputId": "16133239-2ea9-4d7e-f612-b5fe8a455b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('move.v.03')\n",
            "Synset('move.v.03')\n",
            "Synset('move.v.03')\n",
            "Synset('move.v.03')\n",
            "Synset('move.v.03')\n",
            "Synset('move.v.03')\n",
            "Synset('move.v.03')\n",
            "Synset('move.v.03')\n",
            "Synset('move.v.03')\n",
            "Synset('move.v.03')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Observation\n",
        "\n",
        "I feel that WordNet does not work well for verb as the way it dose for nouns. Even though a word might have multiple definitions of a verb, the definitions are not as diverse as the noun definitions. However, WordNet provides more options for verbs than other word forms that are not nouns. Also, WordNet provides a hierarchy of the verb, however, WordNet cannot traverse a verb until entity. But WordNet can provide other words with the same meaning as the verb (or similar). Also, WordNet can define a verb, state the lemmatizations of its, and provide some examples.  \n",
        "\n",
        "The verb I used was dance, and the definition I got is \"move in a graceful and rhythmical way,\" which I believe to be accurate. The examples I got is \"The young girl danced into the room,\" which I also believe is accurate. And the lemma I received is 'dance.v.01.dance'\n",
        "\n",
        "For the WordNet hierarchy, I received this word 'move.v.03', which also similar to dance. "
      ],
      "metadata": {
        "id": "r9EGNPYimXue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  morphy \n",
        "wn.morphy('acting', wn.ADJ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cxQmlX-uqfMw",
        "outputId": "411a810b-ed8c-431e-8069-fa917444ae95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'act'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  morphy \n",
        "wn.morphy('acting', wn.VERB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CJCDAd1MqqAn",
        "outputId": "f63ef607-0bc0-4d82-81fc-fc43c907a9d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'act'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  morphy \n",
        "wn.morphy('acting', wn.NOUN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EsDflipAquph",
        "outputId": "74a62933-1545-466f-b466-fb5da64e6037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'acting'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  morphy \n",
        "wn.morphy('acting', wn.ADJ_SAT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B2pvquHbq2oF",
        "outputId": "51393e27-b4b3-4c44-bb52-c538cb43797b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'acting'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  morphy \n",
        "wn.morphy('acting', wn.ADV)"
      ],
      "metadata": {
        "id": "0ddD3dbRq_sI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select two words and find similarities \n",
        "wn.synsets('work')\n",
        "\n"
      ],
      "metadata": {
        "id": "ME9HRamLr-z9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "50edbb17-966b-48d3-9472-bbc2d7448c6f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('work.n.01'),\n",
              " Synset('work.n.02'),\n",
              " Synset('employment.n.02'),\n",
              " Synset('study.n.02'),\n",
              " Synset('work.n.05'),\n",
              " Synset('workplace.n.01'),\n",
              " Synset('oeuvre.n.01'),\n",
              " Synset('work.v.01'),\n",
              " Synset('work.v.02'),\n",
              " Synset('work.v.03'),\n",
              " Synset('function.v.01'),\n",
              " Synset('work.v.05'),\n",
              " Synset('exercise.v.03'),\n",
              " Synset('make.v.36'),\n",
              " Synset('work.v.08'),\n",
              " Synset('work.v.09'),\n",
              " Synset('work.v.10'),\n",
              " Synset('bring.v.03'),\n",
              " Synset('work.v.12'),\n",
              " Synset('cultivate.v.02'),\n",
              " Synset('work.v.14'),\n",
              " Synset('influence.v.01'),\n",
              " Synset('work.v.16'),\n",
              " Synset('work.v.17'),\n",
              " Synset('work.v.18'),\n",
              " Synset('work.v.19'),\n",
              " Synset('shape.v.02'),\n",
              " Synset('work.v.21'),\n",
              " Synset('knead.v.01'),\n",
              " Synset('exploit.v.01'),\n",
              " Synset('solve.v.01'),\n",
              " Synset('ferment.v.03'),\n",
              " Synset('sour.v.01'),\n",
              " Synset('work.v.27')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets('job')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hV1I9CTULbUw",
        "outputId": "25ff35bd-32eb-46ae-d1a0-9619df628ff9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('occupation.n.01'),\n",
              " Synset('job.n.02'),\n",
              " Synset('job.n.03'),\n",
              " Synset('job.n.04'),\n",
              " Synset('job.n.05'),\n",
              " Synset('job.n.06'),\n",
              " Synset('job.n.07'),\n",
              " Synset('problem.n.01'),\n",
              " Synset('job.n.09'),\n",
              " Synset('job.n.10'),\n",
              " Synset('job.n.11'),\n",
              " Synset('job.n.12'),\n",
              " Synset('caper.n.03'),\n",
              " Synset('job.v.01'),\n",
              " Synset('subcontract.v.01'),\n",
              " Synset('job.v.03'),\n",
              " Synset('speculate.v.04')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = wn.synset('workplace.n.01')\n",
        "w2 = wn.synset('problem.n.01')\n",
        "\n",
        "#wu-palmer:\n",
        "wn.wup_similarity(w1, w2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zNZ32nK1LbEJ",
        "outputId": "8280be30-0133-4fb3-bee1-12994e4c755a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14285714285714285"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.wsd import lesk\n",
        "print(lesk('workplace', 'problem'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cfiookarMOlV",
        "outputId": "3f12d021-3942-41b8-e518-33fe646eb1a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('trouble.n.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Observations\n",
        "\n",
        "First, I found the synsets of two words, and choose one synset of each one. Then I saved the synsets in variables w1 and w2. After that I tested the words similarities using Wu-Palmer and Lesk functions. \n",
        "I have noticed that Wu-Palmer function provide a fraction number between 0 and 1, and the scale is from 0 to 1, 0 means that the words are not similar, and 1 means that the words are very similar. The Wu-Palmer score I got was 0.142, which means that the words I picked were not very similar.\n",
        "\n",
        "The Lesk functions provides word/s that are similar to the picked words. The words I used for both Wu-Palmer and Lesk functions are: workplace and problem. The word I got from the Lesk function is trouble. "
      ],
      "metadata": {
        "id": "P7EW7PDUNcKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#SentiWordNet Summary\n",
        "\n",
        "SentiWordNet is considered a library of WordNet, that provides three results fora word (synset) about positive, negative, and objective indication of the word. For example, we can use words that has negative meaning such as 'mad' and SentiWordNet would provide us with three score about how negative, positive and objective the word is, and the negative result would ultimately be higher than the rest. However, the word 'happy' would provide us with a higher positive score than negative. "
      ],
      "metadata": {
        "id": "j0LlwIDDye3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets('thrilling')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zo2Ru8EjO9jt",
        "outputId": "e13fc0e0-0f2e-4016-d797-b26eecd59c04"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('thrill.v.01'),\n",
              " Synset('thrill.v.02'),\n",
              " Synset('shudder.v.02'),\n",
              " Synset('exhilarate.v.01'),\n",
              " Synset('electrifying.s.01'),\n",
              " Synset('thrilling.s.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select an emotionally charged word.\n",
        "#Find its senti-synsets and output the polarity scores for each word. \n",
        "#Make up a sentence. Output the polarity for each word in the sentence. \n",
        "import nltk\n",
        "nltk.download('sentiwordnet')\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hNmm7Y32N0TS",
        "outputId": "e911d375-2470-4832-8074-238cb3a46f9e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "sentl = list(swn.senti_synsets('electrifying')) \n",
        "for i in sentl:\n",
        "    print(i)\n",
        "\n",
        "    print(\"objective: \", i.obj_score())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vqG8MWzKRZax",
        "outputId": "fead5e1d-6ccc-4d77-a111-6d828c01cd69"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<electrify.v.01: PosScore=0.25 NegScore=0.125>\n",
            "objective:  0.625\n",
            "<electrify.v.02: PosScore=0.0 NegScore=0.0>\n",
            "objective:  1.0\n",
            "<electrify.v.03: PosScore=0.0 NegScore=0.0>\n",
            "objective:  1.0\n",
            "<electrifying.s.01: PosScore=0.25 NegScore=0.5>\n",
            "objective:  0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make up a sentence. Output the polarity for each word in the sentence. \n",
        "s = 'I love the weather today'\n",
        "negative = 0\n",
        "positive  = 0\n",
        "t = s.split()\n",
        "for token in t:\n",
        "    synl = list(swn.senti_synsets(token))\n",
        "    if synl:\n",
        "        word = synl[0]\n",
        "        negative += word.neg_score()\n",
        "        positive += word.pos_score()\n",
        "    \n",
        "print(\"negative scores: \", negative)\n",
        "print('positive scores: ', positive)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BuTvOlGUPxqO",
        "outputId": "3c93f430-8129-48e4-f159-16995b02d99f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative scores:  0.0\n",
            "positive scores:  0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#Observations\n",
        "\n",
        "I selected the word 'electrifying' and created a list of senti_synsets to loop through. Looping through this the senti_synsets provided me with the word and the polarity score for each one. The results I got indicated that the word has more an objective meaning, positive, then negative. \n",
        "For the sentence, I used this \"I love the weather today\" and also used a list of senti_synsets of tokens. The results I reced showed me that the sentence is positive and not negative."
      ],
      "metadata": {
        "id": "HJEir9Dy0foQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Collocation\n",
        " \n",
        "collocation means the likelihood of two exacte words (no other words with similar meaning) occuring together. And NLKT has nine collocation options named as text1 through 9. Collocation can be created or we can use the collocation provided to us from NLKT library. Then we can use the data from the collocation to calculate mutual information. "
      ],
      "metadata": {
        "id": "6UuJg_CMShKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Output collocations for text4, the Inaugural corpus. Select one of the collocations identified by NLTK. \n",
        "#Calculate mutual information. \n",
        "\n",
        "import nltk\n",
        "nltk.download('inaugural')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('webtext')\n",
        "nltk.download('treebank')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')\n",
        "  \n",
        "from nltk.book import *\n",
        "text4.collocations()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "U5urho1nSQ0Z",
        "outputId": "0c525dfe-d4dc-4fb8-fab2-315bf2a96e35"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Package nps_chat is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/genesis.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Introductory Examples for the NLTK Book ***\n",
            "Loading text1, ..., text9 and sent1, ..., sent9\n",
            "Type the name of the text or sentence to view it.\n",
            "Type: 'texts()' or 'sents()' to list the materials.\n",
            "text1: Moby Dick by Herman Melville 1851\n",
            "text2: Sense and Sensibility by Jane Austen 1811\n",
            "text3: The Book of Genesis\n",
            "text4: Inaugural Address Corpus\n",
            "text5: Chat Corpus\n",
            "text6: Monty Python and the Holy Grail\n",
            "text7: Wall Street Journal\n",
            "text8: Personals Corpus\n",
            "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n",
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; American people; Vice President; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = ' '.join(text4.tokens)\n",
        "t[:67]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Uw0kX-4iU5tW",
        "outputId": "226d2b3a-6ac4-4e6e-a672-ba466a820f4c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Fellow - Citizens of the Senate and of the House of Representatives'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "voc = len(set(text4))\n",
        "hg = t.count('and to')/voc\n",
        "print(\"p(and to) = \",hg )\n",
        "h = t.count('and')/voc\n",
        "print(\"p(and) = \", h)\n",
        "g = t.count('to')/voc\n",
        "print('p(to) = ', g)\n",
        "pmi = math.log2(hg / (h * g))\n",
        "print('pmi = ', pmi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1giAz-FWWaKD",
        "outputId": "c5066601-a0e1-4813-c24f-bc956448cb0a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(and to) =  0.017955112219451373\n",
            "p(and) =  0.5833416458852868\n",
            "p(to) =  0.565286783042394\n",
            "pmi =  -4.198929370502643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#Observation \n",
        "I used this sentence 'and to' to calculate the mutual information and receive the PMI results. the occurrence of the sentence was 0.0179, which is very small, but the occurrence of individual words 'and' = 0.5833 and 'to' = 0.565, which is very high, however, the likelihood of them used together is very small. "
      ],
      "metadata": {
        "id": "Q8eLSTNlSfkD"
      }
    }
  ]
}